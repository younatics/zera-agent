import streamlit as st
import pandas as pd
import plotly.express as px
from prompt_tuner import PromptTuner
import os
import logging
import plotly.graph_objects as go

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

st.set_page_config(page_title="Prompt Tuning Visualizer", layout="wide")

st.title("Prompt Tuning Dashboard")

# ëª¨ë¸ ì •ë³´ ì •ì˜
MODEL_INFO = {
    "solar": {
        "name": "Solar",
        "description": "Upstageì˜ Solar ëª¨ë¸",
        "version": "solar-pro"
    },
    "gpt4o": {
        "name": "GPT-4",
        "description": "OpenAIì˜ GPT-4 ëª¨ë¸",
        "version": "gpt-4"
    },
    "claude": {
        "name": "Claude",
        "description": "Anthropicì˜ Claude 3 Sonnet",
        "version": "claude-3-sonnet-20240229"
    }
}

# ê¸°ë³¸ í‰ê°€ í”„ë¡¬í”„íŠ¸
DEFAULT_EVALUATION_PROMPT = """ë‹¹ì‹ ì€ AI ì‘ë‹µì˜ í’ˆì§ˆì„ í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì‘ë‹µì´ ê¸°ëŒ€í•˜ëŠ” ì‘ë‹µê³¼ ì–¼ë§ˆë‚˜ ì˜ ì¼ì¹˜í•˜ëŠ”ì§€ í‰ê°€í•´ì£¼ì„¸ìš”.

ì‹¤ì œ ì‘ë‹µ:
{response}

ê¸°ëŒ€í•˜ëŠ” ì‘ë‹µ:
{expected}

ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”:
1. ì˜ë¯¸ì  ìœ ì‚¬ì„± (ì‘ë‹µì´ ê¸°ëŒ€í•˜ëŠ” ë‚´ìš©ì„ ì–¼ë§ˆë‚˜ ì˜ ì „ë‹¬í•˜ëŠ”ê°€)
2. í†¤ê³¼ ìŠ¤íƒ€ì¼ (ì „ë¬¸ì ì´ê³  ê³µì†í•œ í†¤ì„ ìœ ì§€í•˜ëŠ”ê°€)
3. ì •ë³´ì˜ ì •í™•ì„± (ì˜ëª»ëœ ì •ë³´ë¥¼ í¬í•¨í•˜ì§€ ì•ŠëŠ”ê°€)
4. ì‘ë‹µì˜ ì™„ì„±ë„ (í•„ìš”í•œ ì •ë³´ë¥¼ ëª¨ë‘ í¬í•¨í•˜ëŠ”ê°€)

0.0ì—ì„œ 1.0 ì‚¬ì´ì˜ ì ìˆ˜ë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”.
ì˜ˆì‹œ: 0.85"""

# ì‚¬ì´ë“œë°”ì—ì„œ íŒŒë¼ë¯¸í„° ì„¤ì •
with st.sidebar:
    st.header("íŠœë‹ íŒŒë¼ë¯¸í„°")
    iterations = st.slider("ë°˜ë³µ íšŸìˆ˜", min_value=1, max_value=10, value=3)
    
    # ëª¨ë¸ ì„ íƒ
    model_name = st.selectbox(
        "ëª¨ë¸ ì„ íƒ",
        options=list(MODEL_INFO.keys()),
        format_func=lambda x: f"{MODEL_INFO[x]['name']} ({MODEL_INFO[x]['version']})",
        help="í”„ë¡¬í”„íŠ¸ íŠœë‹ì— ì‚¬ìš©í•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”."
    )
    st.caption(MODEL_INFO[model_name]['description'])
    
    # í‰ê°€ ëª¨ë¸ ì„ íƒ
    evaluator_model = st.selectbox(
        "í‰ê°€ ëª¨ë¸ ì„ íƒ",
        options=list(MODEL_INFO.keys()),
        format_func=lambda x: f"{MODEL_INFO[x]['name']} ({MODEL_INFO[x]['version']})",
        help="ì‘ë‹µ í‰ê°€ì— ì‚¬ìš©í•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”."
    )
    st.caption(MODEL_INFO[evaluator_model]['description'])

# í”„ë¡¬í”„íŠ¸ ì„¤ì •
with st.expander("ì´ˆê¸° í”„ë¡¬í”„íŠ¸ ì„¤ì •", expanded=False):
    initial_prompt = st.text_area(
        "í”„ë¡¬í”„íŠ¸",
        value="You are a helpful AI assistant. Be polite and concise in your responses.",
        height=100,
        help="íŠœë‹ì„ ì‹œì‘í•  ì´ˆê¸° í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”."
    )

# í‰ê°€ í”„ë¡¬í”„íŠ¸ ì„¤ì •
with st.expander("í‰ê°€ í”„ë¡¬í”„íŠ¸ ì„¤ì •", expanded=False):
    evaluation_prompt = st.text_area(
        "í”„ë¡¬í”„íŠ¸",
        value=DEFAULT_EVALUATION_PROMPT,
        height=300,
        help="""ì‘ë‹µì„ í‰ê°€í•  ë•Œ ì‚¬ìš©í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.
{response}ì™€ {expected}ëŠ” ì‹¤ì œ ì‘ë‹µê³¼ ê¸°ëŒ€ ì‘ë‹µìœ¼ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤."""
    )

# CSV íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("Upload your CSV file", type=['csv'])

if uploaded_file is not None:
    try:
        # CSV íŒŒì¼ì„ ì½ì„ ë•Œ ë” ìœ ì—°í•œ íŒŒì‹± ì˜µì…˜ ì‚¬ìš©
        df = pd.read_csv(uploaded_file, 
                        encoding='utf-8',
                        on_bad_lines='skip',  # ë¬¸ì œê°€ ìˆëŠ” ì¤„ì€ ê±´ë„ˆë›°ê¸°
                        quoting=1,  # ëª¨ë“  í•„ë“œë¥¼ ë”°ì˜´í‘œë¡œ ê°ì‹¸ê¸°
                        escapechar='\\')  # ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì ì„¤ì •
        
        # ë°ì´í„°í”„ë ˆì„ í‘œì‹œ
        st.write("Uploaded Data:")
        st.dataframe(df)
        
        # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìƒì„±
        test_cases = []
        for _, row in df.iterrows():
            test_cases.append({
                'input': row['question'],
                'expected_output': row['expected_answer']
            })
        
        # íŠœë‹ ì‹œì‘ ë²„íŠ¼
        if st.button("Start Prompt Tuning", type="primary"):
            # API í‚¤ í™•ì¸
            required_keys = {
                "solar": "SOLAR_API_KEY",
                "gpt4o": "OPENAI_API_KEY",
                "claude": "ANTHROPIC_API_KEY"
            }
            
            missing_keys = []
            for model in [model_name, evaluator_model]:
                key = required_keys[model]
                if not os.getenv(key):
                    missing_keys.append(f"{MODEL_INFO[model]['name']} ({key})")
            
            if missing_keys:
                st.error(f"ë‹¤ìŒ API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤: {', '.join(missing_keys)}")
                st.info("API í‚¤ë¥¼ .env íŒŒì¼ì— ì„¤ì •í•˜ì„¸ìš”.")
            else:
                # í”„ë¡¬í”„íŠ¸ íŠœë„ˆ ì´ˆê¸°í™” ë° ì‹¤í–‰
                tuner = PromptTuner(model_name=model_name, evaluator_model_name=evaluator_model)
                tuner.set_evaluation_prompt(evaluation_prompt)
                
                with st.spinner("í”„ë¡¬í”„íŠ¸ íŠœë‹ ì¤‘..."):
                    results = tuner.tune(initial_prompt, test_cases, iterations=iterations)
                
                # ê²°ê³¼ í‘œì‹œ
                st.header("í”„ë¡¬í”„íŠ¸ íŠœë‹ ê²°ê³¼")
                
                # ìµœê³ ì˜ ê²°ê³¼ í‘œì‹œ
                best_result = max(results, key=lambda x: x['avg_score'])
                st.markdown("### ğŸ† ìµœê³ ì˜ ê²°ê³¼")
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("í‰ê·  ì ìˆ˜", f"{best_result['avg_score']:.2f}")
                with col2:
                    st.metric("ìµœê³  ì ìˆ˜", f"{best_result['best_score']:.2f}")
                with col3:
                    st.metric("ìµœì € ì ìˆ˜", f"{best_result['worst_score']:.2f}")
                with col4:
                    st.metric("í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìˆ˜", len(best_result['detailed_responses']))
                
                st.text_area("ìµœì  í”„ë¡¬í”„íŠ¸", value=best_result['prompt'], height=80)
                st.markdown("---")
                
                # Iterationë³„ë¡œ ê²°ê³¼ í‘œì‹œ
                for i, record in enumerate(results):
                    with st.expander(f"Iteration {i+1} (í‰ê·  ì ìˆ˜: {record['avg_score']:.2f}) - {record['prompt']}", expanded=False):
                        col1, col2, col3 = st.columns(3)
                        with col1:
                            st.metric("í‰ê·  ì ìˆ˜", f"{record['avg_score']:.2f}")
                        with col2:
                            st.metric("ìµœê³  ì ìˆ˜", f"{record['best_score']:.2f}")
                        with col3:
                            st.metric("ìµœì € ì ìˆ˜", f"{record['worst_score']:.2f}")
                        st.markdown("---")
                        
                        # ì ìˆ˜ ë³€í™” ê·¸ë˜í”„
                        st.markdown("#### ì ìˆ˜ ë¶„í¬")
                        scores = [r['score'] for r in record['detailed_responses']]
                        
                        # ë°•ìŠ¤ í”Œë¡¯ê³¼ íˆìŠ¤í† ê·¸ë¨ì„ í•¨ê»˜ í‘œì‹œ
                        fig = go.Figure()
                        
                        # ë°•ìŠ¤ í”Œë¡¯ ì¶”ê°€
                        fig.add_trace(go.Box(
                            y=scores,
                            name='ì ìˆ˜ ë¶„í¬',
                            boxpoints='all',
                            jitter=0.3,
                            pointpos=-1.8,
                            marker_color='#1f77b4'
                        ))
                        
                        # íˆìŠ¤í† ê·¸ë¨ ì¶”ê°€
                        fig.add_trace(go.Histogram(
                            x=scores,
                            name='ì ìˆ˜ ë¶„í¬',
                            nbinsx=10,
                            marker_color='#ff7f0e',
                            opacity=0.5
                        ))
                        
                        fig.update_layout(
                            title='í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë³„ ì ìˆ˜ ë¶„í¬',
                            yaxis_title='ì ìˆ˜',
                            showlegend=False,
                            height=300,
                            barmode='overlay'
                        )
                        
                        st.plotly_chart(fig, use_container_width=True, key=f"score_distribution_{i}")
                        
                        # ìƒì„¸ ê²°ê³¼ í‘œì‹œ
                        st.markdown("#### ìƒì„¸ ê²°ê³¼")
                        for j, response in enumerate(record['detailed_responses']):
                            st.markdown(f"##### í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ {j+1} (ì ìˆ˜: {response['score']:.2f})")
                            
                            # ê°€ë¡œë¡œ ë°°ì¹˜ëœ í‘œ í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ í‘œì‹œ
                            df = pd.DataFrame({
                                'ì§ˆë¬¸': [response['input']],
                                'ì‹¤ì œ ì‘ë‹µ': [response['response']],
                                'ê¸°ëŒ€ ì‘ë‹µ': [response['expected']]
                            })
                            st.dataframe(
                                df,
                                column_config={
                                    "ì§ˆë¬¸": st.column_config.TextColumn(
                                        "ì§ˆë¬¸",
                                        width="large"
                                    ),
                                    "ì‹¤ì œ ì‘ë‹µ": st.column_config.TextColumn(
                                        "ì‹¤ì œ ì‘ë‹µ",
                                        width="large"
                                    ),
                                    "ê¸°ëŒ€ ì‘ë‹µ": st.column_config.TextColumn(
                                        "ê¸°ëŒ€ ì‘ë‹µ",
                                        width="large"
                                    )
                                },
                                hide_index=True,
                                use_container_width=True
                            )
                            st.markdown("---")  # êµ¬ë¶„ì„  ì¶”ê°€
                
    except Exception as e:
        st.error(f"Error processing CSV file: {str(e)}")
        logger.error(f"Error processing CSV file: {str(e)}") 