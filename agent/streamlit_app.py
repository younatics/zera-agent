import streamlit as st
import pandas as pd
import plotly.express as px
from prompt_tuner import PromptTuner
import os
import logging
import plotly.graph_objects as go

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

st.set_page_config(page_title="Prompt Tuning Visualizer", layout="wide")

st.title("Prompt Tuning Dashboard")

# ëª¨ë¸ ì •ë³´ ì •ì˜
MODEL_INFO = {
    "solar": {
        "name": "Solar",
        "description": "Upstageì˜ Solar ëª¨ë¸",
        "version": "solar-pro"
    },
    "gpt4o": {
        "name": "GPT-4",
        "description": "OpenAIì˜ GPT-4 ëª¨ë¸",
        "version": "gpt-4"
    },
    "claude": {
        "name": "Claude",
        "description": "Anthropicì˜ Claude 3 Sonnet",
        "version": "claude-3-sonnet-20240229"
    }
}

# ê¸°ë³¸ í‰ê°€ í”„ë¡¬í”„íŠ¸
DEFAULT_EVALUATION_PROMPT = """ë‹¹ì‹ ì€ AI ì‘ë‹µì˜ í’ˆì§ˆì„ í‰ê°€í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì‘ë‹µì´ ê¸°ëŒ€í•˜ëŠ” ì‘ë‹µê³¼ ì–¼ë§ˆë‚˜ ì˜ ì¼ì¹˜í•˜ëŠ”ì§€ í‰ê°€í•´ì£¼ì„¸ìš”.

ì‹¤ì œ ì‘ë‹µ:
{response}

ê¸°ëŒ€í•˜ëŠ” ì‘ë‹µ:
{expected}

ë‹¤ìŒ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”:
1. ì˜ë¯¸ì  ìœ ì‚¬ì„± (ì‘ë‹µì´ ê¸°ëŒ€í•˜ëŠ” ë‚´ìš©ì„ ì–¼ë§ˆë‚˜ ì˜ ì „ë‹¬í•˜ëŠ”ê°€)
2. í†¤ê³¼ ìŠ¤íƒ€ì¼ (ì „ë¬¸ì ì´ê³  ê³µì†í•œ í†¤ì„ ìœ ì§€í•˜ëŠ”ê°€)
3. ì •ë³´ì˜ ì •í™•ì„± (ì˜ëª»ëœ ì •ë³´ë¥¼ í¬í•¨í•˜ì§€ ì•ŠëŠ”ê°€)
4. ì‘ë‹µì˜ ì™„ì„±ë„ (í•„ìš”í•œ ì •ë³´ë¥¼ ëª¨ë‘ í¬í•¨í•˜ëŠ”ê°€)

0.0ì—ì„œ 1.0 ì‚¬ì´ì˜ ì ìˆ˜ë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ í•˜ì§€ ë§ˆì„¸ìš”.
ì˜ˆì‹œ: 0.85"""

# ì‚¬ì´ë“œë°”ì—ì„œ íŒŒë¼ë¯¸í„° ì„¤ì •
with st.sidebar:
    st.header("íŠœë‹ íŒŒë¼ë¯¸í„°")
    iterations = st.slider("ë°˜ë³µ íšŸìˆ˜", min_value=1, max_value=10, value=3)
    
    # ëª¨ë¸ ì„ íƒ
    model_name = st.selectbox(
        "ëª¨ë¸ ì„ íƒ",
        options=list(MODEL_INFO.keys()),
        format_func=lambda x: f"{MODEL_INFO[x]['name']} ({MODEL_INFO[x]['version']})",
        help="í”„ë¡¬í”„íŠ¸ íŠœë‹ì— ì‚¬ìš©í•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”."
    )
    st.caption(MODEL_INFO[model_name]['description'])
    
    # í‰ê°€ ëª¨ë¸ ì„ íƒ
    evaluator_model = st.selectbox(
        "í‰ê°€ ëª¨ë¸ ì„ íƒ",
        options=list(MODEL_INFO.keys()),
        format_func=lambda x: f"{MODEL_INFO[x]['name']} ({MODEL_INFO[x]['version']})",
        help="ì‘ë‹µ í‰ê°€ì— ì‚¬ìš©í•  ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”."
    )
    st.caption(MODEL_INFO[evaluator_model]['description'])

# í”„ë¡¬í”„íŠ¸ ì„¤ì •
with st.expander("ì´ˆê¸° í”„ë¡¬í”„íŠ¸ ì„¤ì •", expanded=False):
    initial_prompt = st.text_area(
        "í”„ë¡¬í”„íŠ¸",
        value="You are a helpful AI assistant. Be polite and concise in your responses.",
        height=100,
        help="íŠœë‹ì„ ì‹œì‘í•  ì´ˆê¸° í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”."
    )

# í‰ê°€ í”„ë¡¬í”„íŠ¸ ì„¤ì •
with st.expander("í‰ê°€ í”„ë¡¬í”„íŠ¸ ì„¤ì •", expanded=False):
    evaluation_prompt = st.text_area(
        "í”„ë¡¬í”„íŠ¸",
        value=DEFAULT_EVALUATION_PROMPT,
        height=300,
        help="""ì‘ë‹µì„ í‰ê°€í•  ë•Œ ì‚¬ìš©í•˜ëŠ” í”„ë¡¬í”„íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”.
{response}ì™€ {expected}ëŠ” ì‹¤ì œ ì‘ë‹µê³¼ ê¸°ëŒ€ ì‘ë‹µìœ¼ë¡œ ëŒ€ì²´ë©ë‹ˆë‹¤."""
    )

# CSV íŒŒì¼ ì—…ë¡œë“œ
uploaded_file = st.file_uploader("Upload your CSV file", type=['csv'])

if uploaded_file is not None:
    try:
        # CSV íŒŒì¼ì„ ì½ì„ ë•Œ ë” ìœ ì—°í•œ íŒŒì‹± ì˜µì…˜ ì‚¬ìš©
        df = pd.read_csv(uploaded_file, 
                        encoding='utf-8',
                        on_bad_lines='skip',  # ë¬¸ì œê°€ ìˆëŠ” ì¤„ì€ ê±´ë„ˆë›°ê¸°
                        quoting=1,  # ëª¨ë“  í•„ë“œë¥¼ ë”°ì˜´í‘œë¡œ ê°ì‹¸ê¸°
                        escapechar='\\')  # ì´ìŠ¤ì¼€ì´í”„ ë¬¸ì ì„¤ì •
        
        # ë°ì´í„°í”„ë ˆì„ í‘œì‹œ
        st.write("Uploaded Data:")
        st.dataframe(df)
        
        # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìƒì„±
        test_cases = []
        for _, row in df.iterrows():
            test_cases.append({
                'input': row['question'],
                'expected_output': row['expected_answer']
            })
        
        # íŠœë‹ ì‹œì‘ ë²„íŠ¼
        if st.button("Start Prompt Tuning", type="primary"):
            # API í‚¤ í™•ì¸
            required_keys = {
                "solar": "SOLAR_API_KEY",
                "gpt4o": "OPENAI_API_KEY",
                "claude": "ANTHROPIC_API_KEY"
            }
            
            missing_keys = []
            for model in [model_name, evaluator_model]:
                key = required_keys[model]
                if not os.getenv(key):
                    missing_keys.append(f"{MODEL_INFO[model]['name']} ({key})")
            
            if missing_keys:
                st.error(f"ë‹¤ìŒ API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤: {', '.join(missing_keys)}")
                st.info("API í‚¤ë¥¼ .env íŒŒì¼ì— ì„¤ì •í•˜ì„¸ìš”.")
            else:
                # í”„ë¡¬í”„íŠ¸ íŠœë„ˆ ì´ˆê¸°í™” ë° ì‹¤í–‰
                tuner = PromptTuner(model_name=model_name, evaluator_model_name=evaluator_model)
                tuner.set_evaluation_prompt(evaluation_prompt)
                
                with st.spinner("í”„ë¡¬í”„íŠ¸ íŠœë‹ ì¤‘..."):
                    results = tuner.tune(initial_prompt, test_cases, iterations=iterations)
                
                # ê²°ê³¼ í‘œì‹œ
                st.header("í”„ë¡¬í”„íŠ¸ íŠœë‹ ê²°ê³¼")
                
                # ìµœê³ ì˜ ê²°ê³¼ í‘œì‹œ
                best_result = max(results, key=lambda x: x['avg_score'])
                st.markdown("### ğŸ† ìµœê³ ì˜ ê²°ê³¼")
                col1, col2, col3, col4 = st.columns(4)
                with col1:
                    st.metric("í‰ê·  ì ìˆ˜", f"{best_result['avg_score']:.2f}")
                with col2:
                    st.metric("ìµœê³  ì ìˆ˜", f"{best_result['best_score']:.2f}")
                with col3:
                    st.metric("ìµœì € ì ìˆ˜", f"{best_result['worst_score']:.2f}")
                with col4:
                    st.metric("í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ ìˆ˜", len(best_result['detailed_responses']))
                
                st.text_area("ìµœì  í”„ë¡¬í”„íŠ¸", value=best_result['prompt'], height=80)
                st.markdown("---")
                
                # Iterationë³„ë¡œ ê²°ê³¼ í‘œì‹œ
                st.markdown("#### ëª¨ë“  Iteration ê²°ê³¼")
                
                # ëª¨ë“  iterationì˜ ê²°ê³¼ë¥¼ í•˜ë‚˜ì˜ DataFrameìœ¼ë¡œ í†µí•©
                all_results = []
                for i, record in enumerate(results):
                    for j, response in enumerate(record['detailed_responses']):
                        all_results.append({
                            'Iteration': i + 1,
                            'í”„ë¡¬í”„íŠ¸': record['prompt'],
                            'í‰ê·  ì ìˆ˜': record['avg_score'],
                            'í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤': j + 1,
                            'ì§ˆë¬¸': response['input'],
                            'ê¸°ëŒ€ ì‘ë‹µ': response['expected'],
                            'ì‹¤ì œ ì‘ë‹µ': response['response'],
                            'ì ìˆ˜': response['score']
                        })
                
                df_all = pd.DataFrame(all_results)
                st.dataframe(
                    df_all,
                    column_config={
                        "Iteration": st.column_config.NumberColumn(
                            "Iteration",
                            width="small"
                        ),
                        "í”„ë¡¬í”„íŠ¸": st.column_config.TextColumn(
                            "í”„ë¡¬í”„íŠ¸",
                            width="large"
                        ),
                        "í‰ê·  ì ìˆ˜": st.column_config.NumberColumn(
                            "í‰ê·  ì ìˆ˜",
                            format="%.2f",
                            width="small"
                        ),
                        "í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤": st.column_config.NumberColumn(
                            "í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤",
                            width="small"
                        ),
                        "ì§ˆë¬¸": st.column_config.TextColumn(
                            "ì§ˆë¬¸",
                            width="medium"
                        ),
                        "ê¸°ëŒ€ ì‘ë‹µ": st.column_config.TextColumn(
                            "ê¸°ëŒ€ ì‘ë‹µ",
                            width="medium"
                        ),
                        "ì‹¤ì œ ì‘ë‹µ": st.column_config.TextColumn(
                            "ì‹¤ì œ ì‘ë‹µ",
                            width="medium"
                        ),
                        "ì ìˆ˜": st.column_config.NumberColumn(
                            "ì ìˆ˜",
                            format="%.2f",
                            width="small"
                        )
                    },
                    hide_index=True,
                    use_container_width=True
                )
                
                st.markdown("---")
                
    except Exception as e:
        st.error(f"Error processing CSV file: {str(e)}")
        logger.error(f"Error processing CSV file: {str(e)}") 