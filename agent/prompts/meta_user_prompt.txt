# PROMPT OPTIMIZATION TASK

## 1. TASK CONTEXT
Task Type:  
{task_type}  

Task Description:  
{task_description}

Note: Some tasks require strict output format (e.g., classification label in parentheses); others reward clear reasoning more than structure.

## 2. PERFORMANCE SNAPSHOT
- Examine the following prompt cases and outputs:
{random_cases}

Evaluate:
- Are prompts enabling free-form reasoning before enforcing format?
- Is output formatting only constrained at the final answer?
- Are instructions concise and focused on structure-critical aspects?
- Do expected outputs imply any format or reasoning patterns worth learning?
- What structural elements consistently correlate with higher performance?
- Do prompts overfit to formatting prematurely, stifling natural reasoning?

## 3. PROMPT REVIEW
Recent Prompt History:  
{recent_prompts}

Best Performing Prompt:  
{formatted_best_prompt}

Current System Prompt:  
{system_prompt}

Current User Prompt:  
{user_prompt}

## 4. TASK IMPROVEMENT STRATEGY (4 Steps)

1. **Analyze Prompt Failures**  
   - Review evaluation logs to identify specific weaknesses in reasoning, formatting, or clarity.
2. **Identify Task Demands**  
   - Understand whether the task emphasizes reasoning depth, structural formatting, or both.  
   - Determine whether shallow reasoning is a persistent issue; if so, explicitly reinforce multi-step logical analysis, encourage interpretation of latent relationships, and introduce hints for abstraction or pattern discovery.
3. **Select Prioritized Improvements**  
   - Choose 1–2 focus areas (e.g., scaffolding, brevity, example inclusion) based on failure mode.
4. **Draft Hypothesis for Next Iteration**  
   - Define what the improved prompt should do better and how it addresses prior weaknesses.

## 5. PROMPT GENERATION STRATEGY

Your objective is to generate improved prompts that:
- Prioritize natural reasoning before enforcing output structure
- Apply formatting only when necessary—typically at final answer stage
- Stay short, direct, and focused on the task’s outcome
- Include few-shot examples in the USER_PROMPT only when essential for structure or reliability

Additional Consideration:
- Analyze whether current task formulations encourage superficial reasoning. If tasks are too templated or overly predictable, prompts should challenge the model to perform deeper semantic analysis, consider dependencies, and verify logic step-by-step before formatting the final answer.
- If the task permits, design prompts to elicit mental simulation, abstract reasoning, or transformation—beyond surface-level cues.
- When aiming for deep reasoning, incorporate scaffolding language such as 'examine step-by-step', 'evaluate alternatives', or 'infer latent intent' to guide model behavior beyond shallow parsing.
- Consider surfacing key "reasoning hints" learned from prior errors. These may include examples of misinterpretations, overlooked structural rules, or common semantic traps. Rather than solely training the model to answer a given question, equip it to handle future variations of the task—especially if input phrasings change or require abstraction. Incorporate such hints directly into the USER_PROMPT in a concise, interpretable form. If appropriate, support with example question-answer pairs that demonstrate correct reasoning and output structure.
- If stagnation is observed, simplify, and separate reasoning from structure more explicitly
- If necessary, you may rewrite or revise the question itself to better elicit reasoning depth while maintaining the output intent and format.

## 6. FINAL PROMPT CONSTRUCTION TEMPLATE

### FINAL PROMPT OUTPUT

TASK_TYPE:
[Main task type] ([Sub-task type])

TASK_DESCRIPTION:
[Enhanced task description with clear output requirements]

SYSTEM_PROMPT:
[Optimized system prompt]

USER_PROMPT:
[Optimized user prompt that clearly guides the model’s behavior, with examples or format cues if appropriate. Style and structure should reflect the task’s reasoning depth, format sensitivity, and output clarity needs. If the task benefits from reasoning, guide the model to write out its reasoning visibly first—step-by-step—before presenting the final answer clearly at the end. Ensure the final answer is presented in the required format and appears on a separate line if specified by the task. The prompt should never include a new question; only include format guidance and optional few-shot examples.]

- TASK_HINTS:
  - [Insert bullet-pointed hints derived from prior errors]

- FEW_SHOT_EXAMPLES:
  Example:
  Question: [Insert example question]  
  Answer: [Insert correct answer]